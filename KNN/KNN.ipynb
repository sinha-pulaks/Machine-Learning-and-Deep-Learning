{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to examine the Breast Cancer Dataset using python sklearn library to model K-nearest neighbor algorithm.\n",
    "After modeling the knn classifier, we are going to use the trained knn model to predict whether the patient is suffering from the benign tumor or malignant tumor. The greatness of using  Sklearn is that it provides us the functionality to implement machine learning algorithms in a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of 10 continuous attributes and 1 target class attributes. Class attribute shows the observation result, whether the patient is suffering from the benign tumor or malignant tumor. Benign tumors do not spread to other parts while the malignant tumor is cancerous. The dataset was collected & openly distributed so as to find out some patterns from this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breast Cancer Data Set Attribute Information:\n",
    "1. Sample code number: id number\n",
    "2. Clump Thickness: 1 – 10\n",
    "3. Uniformity of Cell Size: 1 – 10\n",
    "4. Uniformity of Cell Shape: 1 – 10\n",
    "5. Marginal Adhesion: 1 – 10\n",
    "6. Single Epithelial Cell Size: 1 – 10\n",
    "7. Bare Nuclei: 1 – 10\n",
    "8. Bland Chromatin: 1 – 10\n",
    "9. Normal Nucleoli: 1 – 10\n",
    "10. Mitoses: 1 – 10\n",
    "11. Class: (2 for benign, 4 for malignant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "To model the knn classifier using the Breast Cancer data for predicting whether a patient is suffering from the benign tumor or malignant tumor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python packages used:\n",
    "\n",
    "NumPy\n",
    "\n",
    "NumPy is a Numeric Python module. It provides fast mathematical functions.\n",
    "\n",
    "Numpy provides robust data structures for efficient computation of multi-dimensional arrays & matrices.\n",
    "\n",
    "We used numpy to read data files into numpy arrays and data manipulation.\n",
    "\n",
    "\n",
    "\n",
    "Scikit-Learn\n",
    "\n",
    "It’s a machine learning library. It includes various machine learning algorithms.\n",
    "\n",
    "We are using its Imputer, train_test_split, KNeighborsClassifier, accuracy_score algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using breast cancer data. You can download it from archive.ics.uci.edu website. For importing the data and manipulating it, we are going to use numpy arrays.\n",
    "Using genfromtxt() method, we are importing our dataset into the 2d numpy array. You can import text files using this function. We are passing 3 parameters:\n",
    "\n",
    "fname\n",
    "\n",
    "It handles the filename with extension.\n",
    "\n",
    "delimiter\n",
    "\n",
    "The string used to separate values. In our dataset “,”(comma) is the separator.\n",
    "\n",
    "dtype\n",
    "\n",
    "It handles data type of variables.\n",
    "\n",
    "All the values are numeric in our database. But some values are missing and are replaced by “?”. So, we will have to perform data imputation. Due to this reason, we are using float dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = np.genfromtxt(\n",
    " fname ='breast-cancer-wisconsin.data', delimiter= ',', dtype= float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above code we have imported our data into a 2d numpy array.\n",
    "\n",
    "len(): Function to find out the no. of records in our data.\n",
    "\n",
    "str(): Function to get an idea about the basic structure of data.\n",
    "\n",
    "shape: To get array dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length::  699\n",
      "Dataset::  [[1.000025e+06 5.000000e+00 1.000000e+00 ... 1.000000e+00 1.000000e+00\n",
      "  2.000000e+00]\n",
      " [1.002945e+06 5.000000e+00 4.000000e+00 ... 2.000000e+00 1.000000e+00\n",
      "  2.000000e+00]\n",
      " [1.015425e+06 3.000000e+00 1.000000e+00 ... 1.000000e+00 1.000000e+00\n",
      "  2.000000e+00]\n",
      " ...\n",
      " [8.888200e+05 5.000000e+00 1.000000e+01 ... 1.000000e+01 2.000000e+00\n",
      "  4.000000e+00]\n",
      " [8.974710e+05 4.000000e+00 8.000000e+00 ... 6.000000e+00 1.000000e+00\n",
      "  4.000000e+00]\n",
      " [8.974710e+05 4.000000e+00 8.000000e+00 ... 4.000000e+00 1.000000e+00\n",
      "  4.000000e+00]]\n",
      "Dataset Shape::  (699, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Length:: \", len(cancer_data))\n",
    "print(\"Dataset:: \", str(cancer_data))\n",
    "print(\"Dataset Shape:: \", cancer_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cancer dataset’s first column consists of patient’s id. To make this prediction process unbiased, we should remove this patient id. We can use numpy delete() method for this operation.\n",
    "\n",
    "delete(): It returns a new transformed array. Three parameters should to passed.\n",
    "    \n",
    "\n",
    "arr: It holds the array name.\n",
    "    \n",
    "obj: It indicates which sub-arrays to remove.\n",
    "    \n",
    "axis: The axis along which to delete. axis = 1 is used for columns & axis = 0 for rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = np.delete(arr = cancer_data, obj= 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  1.,  1., ...,  1.,  1.,  2.],\n",
       "       [ 5.,  4.,  4., ...,  2.,  1.,  2.],\n",
       "       [ 3.,  1.,  1., ...,  1.,  1.,  2.],\n",
       "       ...,\n",
       "       [ 5., 10., 10., ..., 10.,  2.,  4.],\n",
       "       [ 4.,  8.,  6., ...,  6.,  1.,  4.],\n",
       "       [ 4.,  8.,  8., ...,  4.,  1.,  4.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we wish to divide the dataset into feature & label dataset. i.e., feature data is predictor variables they will help us to predict labels(criterion variable). Here, first 9 columns include continuous variables that will help us to predict whether a patient is having the benign tumor or malignant tumor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer_data[:,range(0,9)]\n",
    "Y = cancer_data[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2., 4., 2., 2., 2., 2., 2., 2., 4., 2., 4., 4., 2.,\n",
       "       2., 4., 2., 4., 4., 2., 4., 2., 4., 2., 2., 2., 2., 2., 2., 4., 2.,\n",
       "       2., 2., 4., 2., 4., 4., 2., 4., 4., 4., 4., 2., 4., 2., 2., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 2., 4., 4., 2., 4., 2., 4.,\n",
       "       4., 2., 2., 4., 2., 4., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 4.,\n",
       "       4., 4., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 4., 4., 4., 4.,\n",
       "       2., 4., 4., 4., 4., 4., 2., 4., 2., 4., 4., 4., 2., 2., 2., 4., 2.,\n",
       "       2., 2., 2., 4., 4., 4., 2., 4., 2., 4., 2., 2., 2., 4., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 4., 2., 2., 2., 4., 2., 2., 4., 2., 4., 4.,\n",
       "       2., 2., 4., 2., 2., 2., 4., 4., 2., 2., 2., 2., 2., 4., 4., 2., 2.,\n",
       "       2., 2., 2., 4., 4., 4., 2., 4., 2., 4., 2., 2., 2., 4., 4., 2., 4.,\n",
       "       4., 4., 2., 4., 4., 2., 2., 2., 2., 2., 2., 2., 2., 4., 4., 2., 2.,\n",
       "       2., 4., 4., 2., 2., 2., 4., 4., 2., 4., 4., 4., 2., 2., 4., 2., 2.,\n",
       "       4., 4., 4., 4., 2., 4., 4., 2., 4., 4., 4., 2., 4., 2., 2., 4., 4.,\n",
       "       4., 4., 2., 2., 2., 2., 2., 2., 4., 4., 2., 2., 2., 4., 2., 4., 4.,\n",
       "       4., 2., 2., 2., 2., 4., 4., 4., 4., 4., 2., 4., 4., 4., 2., 4., 2.,\n",
       "       4., 4., 2., 2., 2., 2., 2., 4., 2., 2., 4., 4., 4., 4., 4., 2., 4.,\n",
       "       4., 2., 2., 4., 4., 2., 4., 2., 2., 2., 4., 4., 2., 4., 2., 4., 4.,\n",
       "       2., 2., 4., 2., 2., 2., 4., 2., 2., 2., 4., 4., 2., 2., 4., 2., 2.,\n",
       "       4., 2., 2., 4., 2., 4., 4., 4., 2., 2., 4., 4., 2., 4., 2., 2., 4.,\n",
       "       4., 2., 2., 2., 4., 2., 2., 2., 4., 4., 2., 2., 2., 4., 2., 2., 4.,\n",
       "       4., 4., 4., 4., 4., 2., 2., 2., 2., 4., 4., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 4., 2., 2., 2., 2., 4., 2., 2., 2., 2.,\n",
       "       4., 2., 2., 2., 2., 2., 2., 2., 2., 4., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 4., 2., 4., 2., 4., 2., 2., 2., 2., 4., 2., 2., 2.,\n",
       "       4., 2., 4., 2., 2., 2., 2., 2., 2., 2., 4., 4., 2., 2., 2., 4., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 4., 2., 2., 2., 4., 2., 4., 4., 4., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 4., 4., 4., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 4., 2., 2., 4., 4., 2., 2., 2., 4., 4., 4., 2., 4., 2.,\n",
       "       4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 4., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 4., 4., 2., 2., 2., 4., 2., 2., 4., 4., 2., 2., 2.,\n",
       "       2., 2., 2., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 4., 2., 2., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 4., 2., 2., 4., 4., 4., 4., 2., 2., 4., 2., 2., 2.,\n",
       "       2., 2., 2., 4., 4., 2., 2., 2., 4., 2., 4., 2., 4., 4., 4., 2., 4.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 4., 4., 4., 2., 2., 4., 2., 4., 4.,\n",
       "       4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 4., 2., 2.,\n",
       "       2., 2., 2., 2., 4., 2., 2., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 4., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 4., 4., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       4., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 4., 2., 2., 2., 2., 4.,\n",
       "       4., 4.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  1.,  1., ...,  3.,  1.,  1.],\n",
       "       [ 5.,  4.,  4., ...,  3.,  2.,  1.],\n",
       "       [ 3.,  1.,  1., ...,  3.,  1.,  1.],\n",
       "       ...,\n",
       "       [ 5., 10., 10., ...,  8., 10.,  2.],\n",
       "       [ 4.,  8.,  6., ..., 10.,  6.,  1.],\n",
       "       [ 4.,  8.,  8., ..., 10.,  4.,  1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Imputation:\n",
    "Imputation is a process of replacing missing values with substituted values. In our dataset, some columns have missing values. We can replace missing values with mean, median, mode or any particular value.\n",
    "Sklearn provides Imputer() method to perform imputation in 1 line of code. We just need to define missing_values, axis, and strategy. We are using “median” value of the column to substitute with the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "imp = Imputer(missing_values='NaN', strategy='median')\n",
    "X = imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rain, Test data split:\n",
    "For dividing data into train data & test data. We are using train_test_split() method by sklearn.\n",
    "\n",
    "train_test_split(): We are using 4 parameters X, Y, test_size, random_state\n",
    "\n",
    "X, Y:  X is a numpy array consisting of feature dataset & Y contains labels for each record.\n",
    "\n",
    "\n",
    "test_size: It represents the size of test data needs to split. If we use 0.4, it indicates 40% of data should be separated and saved as testing data.\n",
    "\n",
    "random_state: It’s pseudo-random number generator state used for random sampling. If you want to replicate our results, then use the same value of random_state.\n",
    "\n",
    "Now, X_train & y_train are training datasets. X_test & y_test are testing datasets.\n",
    "y_train & y_test are 2d numpy arrays with 1 column. To convert it into a 1d array, we are using ravel()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    " X, Y, test_size = 0.3, random_state = 100)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier(): This is the classifier function for KNN. It is the main function for implementing the algorithms. Some important parameters are:\n",
    "\n",
    "n_neighbors: It holds the value of K, we need to pass and it must be an integer. If we don’t give the value of n_neighbors then by default, it takes the value as 5.\n",
    "\n",
    "Weights: It holds a string value i.e., name of the weight function. The Weight function used in prediction. It can hold values like ‘uniform’ or ‘distance’ or any user defined function.\n",
    "‘uniform’ weight used when all points in the neighborhood are weighted equally. Default value for weights taken as ‘uniform’\n",
    "‘distance’ weight used for giving closer neighbors- higher weight and far neighbors-less weight, i.e., weight points by the inverse of their distance.\n",
    "user defined function we can call the user defined functions. The user defined function can used when we want to produce custom weight values. It accepts distance values and returns an array of weights.\n",
    "\n",
    "algorithm: It specifies algorithm which should be used to compute the nearest neighbors. It can values like ‘auto’, ‘ball_tree’, ‘kd_tree’, brute’. It is an optional parameter.\n",
    "a) ‘ball_tree’ , ‘kd_tree’ are used to implement ball tree algorithm. These are special kind of data structures for space partitioning.\n",
    "b) ‘brute’ is used to implement brute-force search algorithm.\n",
    "c) ‘auto’ is used to give control to the system. By using ‘auto’, it automatically decides the best algorithm according to values of training data.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.fit(): A fit method is used to fit the model. It is passed with two parameters:X and Y. For training data fitting on KNN algorithm, this needs to call.\n",
    "X: It consists of training data with features.\n",
    "Y: It consists of training data with labels.predict(): It predicts class labels for the data provided as its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  95.23809523809523 % for K-Value: 1\n",
      "Accuracy is  93.33333333333333 % for K-Value: 2\n",
      "Accuracy is  95.71428571428572 % for K-Value: 3\n",
      "Accuracy is  95.23809523809523 % for K-Value: 4\n",
      "Accuracy is  95.71428571428572 % for K-Value: 5\n",
      "Accuracy is  94.76190476190476 % for K-Value: 6\n",
      "Accuracy is  94.76190476190476 % for K-Value: 7\n",
      "Accuracy is  94.28571428571428 % for K-Value: 8\n",
      "Accuracy is  94.76190476190476 % for K-Value: 9\n",
      "Accuracy is  94.28571428571428 % for K-Value: 10\n",
      "Accuracy is  94.28571428571428 % for K-Value: 11\n",
      "Accuracy is  94.76190476190476 % for K-Value: 12\n",
      "Accuracy is  94.76190476190476 % for K-Value: 13\n",
      "Accuracy is  93.80952380952381 % for K-Value: 14\n",
      "Accuracy is  93.80952380952381 % for K-Value: 15\n",
      "Accuracy is  93.80952380952381 % for K-Value: 16\n",
      "Accuracy is  93.80952380952381 % for K-Value: 17\n",
      "Accuracy is  93.80952380952381 % for K-Value: 18\n",
      "Accuracy is  93.80952380952381 % for K-Value: 19\n",
      "Accuracy is  93.80952380952381 % for K-Value: 20\n",
      "Accuracy is  93.80952380952381 % for K-Value: 21\n",
      "Accuracy is  93.80952380952381 % for K-Value: 22\n",
      "Accuracy is  93.80952380952381 % for K-Value: 23\n",
      "Accuracy is  93.80952380952381 % for K-Value: 24\n",
      "Accuracy is  93.80952380952381 % for K-Value: 25\n"
     ]
    }
   ],
   "source": [
    "for K in range(25):\n",
    " K_value = K+1\n",
    " neigh = KNeighborsClassifier(n_neighbors = K_value, weights='uniform', algorithm='auto')\n",
    " neigh.fit(X_train, y_train) \n",
    " y_pred = neigh.predict(X_test)\n",
    " print(\"Accuracy is \", accuracy_score(y_test,y_pred)*100,\"% for K-Value:\",K_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 1., 1., 2., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
